{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9a3446",
   "metadata": {},
   "source": [
    "# CONCLUSIONES FINALES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2149e970",
   "metadata": {},
   "source": [
    "A lo largo de este proyecto hemos desarrollo 9 notebooks y este décimo notebook tiene por objetivo plasmar las conclusiones más importantes alcanzadas a lo largo de estos cuadernos:\n",
    "\n",
    "- 01_Exploracion_general\n",
    "- 02_Tratamiento_correlaciones_missing_outlier\n",
    "- 03_Vars_Selection\n",
    "- 04_Feature_Engineering\n",
    "- 05_Muestreos\n",
    "- 06_Modelizacion_sel\n",
    "- 07_Modelizacion_red\n",
    "- 08_Optimizacionparam_y_Metricas\n",
    "- 09_Explicabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85ae66",
   "metadata": {},
   "source": [
    "### Del notebook 1 (01_Exploracion_general) concluimos: \n",
    "\n",
    "- El **objetivo de este estudio** es predecir, antes de conceder un servicio financiero a una persona, el suceso de fraude o no fraude con un dataset que contiene 32 variables categóricas, numéricas y de tipo texto.\n",
    "\n",
    "- La **variable objetivo es 'fraud_bool'** la cual toma los valores 0 (la solicitud no es fraudulenta) y 1 (sí es fraudulenta), tomando el valor 0 en el casi 99% de las observaciones.\n",
    "\n",
    "- A continuación se muestran las variables que contienen **valores missings** al tomar el valor -1: prev_address_months_count, bank_months_count, current_address_months_count, session_length_in_minutes, device_distinct_emails_8w. Por su parte, la variable intended_balcon_amount posee valores missing al tomar valores negativos. Al aplicar un umbral del 90%, ninguna variable supera el límite de missings. Con un umbral del 50%, dos variables superan este límite, lo que podría reducir la dimensión del dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7a2da",
   "metadata": {},
   "source": [
    "### Del notebook 2 (02_Tratamiento_correlaciones_missing_outlier) concluimos que:\n",
    "\n",
    "- El dataset objeto de estudio dispone de variables categóricas, números enteros y variables continuas por lo que 5 variables han sido transformadas a **formato decimal**.\n",
    "- El conjunto de datos está **desbalanceado** (alrededor de un 99% de las observaciones tienen lugar cuando la variable objetivo 'fraud_bool'= 0).\n",
    "\n",
    "- **Tratamiento variables numéricas**: \n",
    "     - Tras analizar los **outliers**, no hemos encontrado outliers significativos que puedan dañar el análisis.\n",
    "    \n",
    "     - **Correlaciones**: Observamos una elevada relación entre 'velocity_6h', 'velocity_24h', y 'velocity_4w', por lo que vamos a crear una variable que recoja la información de las tres velocidades con su media aritmética en el apartado de selección de variables.\n",
    "         Además podemos destacar que, en valor absoluto, las variables más correlacionadas de la matriz superior son 'month' y 'velocity_4w' con un 84,80% de correlación.También observamos una alta correlación negativa entre 'customer_age' y 'date_of_birth_distinct_emails_4w' por lo tanto consideraremos eliminar una de ellas en selección de variables si lo vemos necesario.\n",
    "        No observamos ninguna |correlación| > 0.2 con respecto a la variable objetivo, lo que sería una indicación de que va a ser complicado realizar predicciones importantes.\n",
    "        Por último, observamos una correlación significativa entre \"proposed_credit_limit\" y \"credit_risk_score\" lo cual tiene sentido debido a que la primera variable influye en el cálculo de la segunda. Puesto que ambas variables nos parecen relevantes en principio ninguna será eliminada del conjunto de datos.\n",
    "    \n",
    "    - **Valores nulos**: \n",
    "        El mayor porcentaje de missings se corresponde con las variables **'intended_balcon_amount'** y **'prev_address_months_count'** (742523 y 712920\tmissings, respectivamente). En primer lugar, es comprensible el alto número de missings encontrados en la variable 'prev_address_months_count', puesto que es altamente posible que muchos de los solicitantes no se hayan mudado a otra residencia. En segundo lugar, el elevado número de missings en la variable 'intended_balcon_amount' indica que casi nunca se introduce dinero al iniciar una aplicación. Eso sumado a que los gráficos boxplots analizados anteriormente son muy parecidos, indica que esta variable no sería muy útil para el estudio. La añadimos a la lista de variables que consideraremos eliminar.\n",
    "        Otra variable que presenta un elevado número de missings es **'bank_months_count'** y esta variable, aunque con un 25% de missings, podría tener importancia en nuestro estudio puesto que como vimos en los boxplots anteriores.\n",
    "\n",
    "- **Tratamiento variables categóricas**: \n",
    "    la relación existente entre las variables categóricas y la variable objetivo son muy bajas, siendo la mayor la relativa a 'housing_status'(0.1148)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee45750",
   "metadata": {},
   "source": [
    "### Del notebook 3 (03_Vars_Selection) concluimos que: \n",
    "\n",
    "- Se ha **eliminado la variable 'device_fraud_count'** al únicamente tomar el valor 0.\n",
    "- Para poder introducir las variables categóricas en los métodos de regularización de variables, hemos **pasado las variables categóricas a numéricas**. Con anterioridad a la selección de variables se ha llevado a cabo la **estandarización de las variables**  y la creación del dataframe **'pd_fraud_std'**.\n",
    "- Las **regularizaciones de Ridge y Lasso al establecer un threshold=0.2 seleccionan las mismas 12 variables de las 30 con las que cuenta 'pd_fraud_std'**. Observamos que los mayores coeficientes otorgados por Lasso son a las variables 'housing_status', 'has_other_cards', y 'phone_home_valid' por lo que seguiremos teniéndolas en cuenta en futuros análisis previos a la realización de los algoritmos.\n",
    "- Sin embargo, consideramos que por el significado que cada variable da al conjunto de datos **ninguna otra variable sería susceptible de ser eliminada por ahora**.\n",
    "- **RFE**: al observar las variables seleccionadas y ver que no se han incluido variables como 'housing_status' o 'income' las cuales poseen las correlaciones más altas con la variable objetivo y que son las que más valor obtienen con Lasso o Ridge **decidimos no considerar la selección por RFE en nuestro análisis**.\n",
    "- Al analizar en mayor profundidad las **variables que comentamos en el notebook 2 que presentaban más de un 70% de valores missings** ('prev_address_months_count' y 'intended_balcon_amount') se concluye que:\n",
    "    - Comprobamos que los valores de la variable 'prev_address_months_count' aunque no sean muy variados, en los boxplot del notebook 2 se observan distribuciones diferentes entre fraude y no fraude. Eso, sumado a que tanto Lasso como Ridge la incluyen entre las 12 variables seleccionadas nos hace decantarnos por dejarla en el dataset.\n",
    "    \n",
    "    - Por otro lado, con respecto a la variable 'intended_balcon_amount' hemos comprobado que, aunque presenta también un porcentaje mayor al 70% de valores faltantes, sus valores únicos positivos (puesto que todos los negativos son missings) suman 257137. Por lo tanto, consideramos que esta variable debe permanecer en el conjunto de datos.\n",
    "- El datataset **'pd_fraud_reduced'** es sobre el que hemos eliminado variables que no aportan y sobre el que haremos combinaciones de variables con altas correlaciones en el próximo notebook. Además, hemos decidido crear uno nuevo únicamente con las 12 variables seleccionadas por las regularizaciones Ridge y Lasso al que llamaremos **'pd_fraud_selection'**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15252320",
   "metadata": {},
   "source": [
    "### Del notebook 4 (04_Feature_Engineering) concluimos que:\n",
    "\n",
    "- En primer lugar, se ha realizado la **división de los datasets 'pd_fraud_reduced' y 'pd_fraud_selection' en conjunto de entrenamiento y test (80% y 20%, respectivamente)**. \n",
    "\n",
    "- Se ha realizado como **combinación de variables** en el dataset 'pd_fraud_reduced' la media aritmética de 'velocity_6h', 'velocity_24h', y 'velocity_4w' en una nueva variable llamada 'mean velocities'. Por tanto, las variables originales han sido eliminadas del conjunto de datos para evitar la duplicidad. \n",
    "\n",
    "- Se ha **estandarizado el conjunto de entrenamiento de los datasets 'pd_fraud_reduced' y 'pd_fraud_selection'** almacenándose dichos datos estandarizados en 'X_pd_fraud_red_train_std' y 'X_pd_fraud_sel_train_std', respectivamente. \n",
    "\n",
    "- Respecto a la **imputación de missings** se van a imputar únicamente los correspondientes a la variable 'intended_balcon_amount' (todos sus valores negativos) en 'pd_fraud_reduced' y 'X_pd_fraud_red_train_std'  dado que el resto de variables con valores ausentes ya están codificadas e imputarlos por otro valor como puede ser la  mediana haría que nuestros datos estuviesen sesgados. \n",
    "\n",
    "- Dado que para la regularizaciones de  Ridge y Lasso fue necesaria la **codificación de las variables categóricas** en este notebook no ha sido necesario realizarlo de nuevo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a4e4f",
   "metadata": {},
   "source": [
    "### Del notebook 5 (05_Muestreos) concluimos que:\n",
    "\n",
    "- En primer lugar, se ha realizado **la separación del train en train y validation (80% y 20%, respectivamente)** puesto que los muestreos no no se pueden aplicar sobre la validación.\n",
    "- Posteriormente se han llevado a cabo **los muestreos de estratificado, oversampling y undersampling** y **consideramos más pertinente utilizar el undersampling** puesto que es preferible para conjuntos de datos grandes, como con el que estamos trabajando. \n",
    "- Al optar por el undersampling, se busca **equilibrar las clases eliminando instancias de la clase mayoritaria**, asegurando así que la representación de la clase minoritaria sea más destacada durante el proceso de aprendizaje. Esta estrategia permite mejorar la capacidad del modelo para generalizar patrones en la clase minoritaria, sin sacrificar información crítica en el conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37408aeb",
   "metadata": {},
   "source": [
    "### De los notebooks 6 (06_Modelizacion_sel) y 7 (07_Modelizacion_red) concluimos que:\n",
    "\n",
    "- En estos dos notebooks hemos **aplicado los siguientes algoritmos**: Modelo base con imputación a la clase mayoritaria, Árbol de decisión, Bayes, Support Vector Machine, Random Forest, BaggingClassifier, XGBoost, AdaBoosting y LightGBM. El notebook 6 sobre los **datasets que contienen las variables seleccionadas por los datasets de Ridge y Lasso**:'X_train_sel_und', 'X_val_sel', 'y_train_sel_std_und' e 'y_val_sel'. El notebook 7 con los conjuntos de datos obtenidos tras la **selección de variables y la feature ingeneering realizadas previamente**: 'X_train_red_und', 'X_val_red', 'y_train_red_und' e 'y_val_red'.\n",
    "\n",
    "- Los conjuntos de datos estandarizados no se han empleado en estos dos cuadernos ya que los **algoritmos** implementados **no se centran en problemas de regresión**.\n",
    "\n",
    "- Además, cabe destacar que únicamente se han utilizado los **conjuntos de datos balanceados con la técnica del undersampling en el train** (la validación está sin balancear).\n",
    "\n",
    "- Se obtiene **mejores rendimientos al modelizar con los datasets obtenidos de la selección de variables y feature engineering realizadas en anteriores notebooks ('red')  que con los datasets de las variables seleccionadas por las regularizaciones de Ridge y Lasso ('sel') para todos los algoritmos**. Por ello, nos hemos decantado por estos datasets al proporcionar mejores valores en métricas como f1-score.\n",
    "\n",
    "- Notebook 6: **El modelo que presenta los mayores f1-score de los datasets 'selected' es AdaBoosting** con un 89% y 8% de aciertos para los casos en los que la variables objetivo toma 0 y 1, respectivamente. Siendo el segundo mejor modelo en relación con estas métricas LightGBM que presenta unos valores bastante similares al anterior modelo (89% y 7%, respectivamente).\n",
    "\n",
    "- Notebook 7: Los modelos que presentan los mayores f1-scores y por tanto los **candidatos a ser los mejores modelos para este proyecto son LightGBM y AdaBoosting** de los datasets 'reduced' con unos valores ambos de un 90% y 9% de aciertos cuando la variable objetivo toma los valores 0 y 1, respectivamente. \n",
    "\n",
    "- En el notebook 7 se ha llevado a cabo un **análisis de importancia** con un Random Forest y es **respaldado por conclusiones alcanzadas anteriormente** acerca de la importancia de variables como 'housing_status', 'current_adress_months_count' y 'credit_risk_score'. Por el contrario, cabe señalar que los resultados de dicho análisis **no coinciden en su totalidad con las variables seleccionadas por las regularizaciones de Ridge y Lasso**. De todos modos, en términos generales la **importancia de las variables no es muy significativa**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284979c6",
   "metadata": {},
   "source": [
    "### Del notebook 8 (08_Optimizacionparam_y_Metricas) concluimos que:\n",
    "\n",
    "\n",
    "- En primer lugar, **se ha incluido en el test la nueva variable ('mean_velocities')** resultado de la combinación de otras tres variables originales del conjunto de datos, eliminando estas otras tres variables del test.\n",
    "\n",
    "- En segundo lugar se ha **optimizado los parámetros de los modelos seleccionados** en el anterior notebook como candidatos a ganadores (LightGBM y AdaBoosting de los datasets 'red') a través de la búsqueda grid, obteniéndose:\n",
    "    - Para LightGBM como mejores parámetros a 'max_depth': 6, 'min_data_in_leaf': 500 y 'num_leaves': 32\n",
    "    - Para AdaBoosting como mejores parámetros a 'learning_rate': 1.1 y 'n_estimators': 200\n",
    "\n",
    "- En tercer lugar, **se han aplicado distintas métricas** para evaluar estos dos modelos con sus parámetros ya optimizados: matriz de confusión, curva Roc, curva de ganancias, curva Lift, curva de precisión y sensibilidad y curva F1-Score. Tras evaluar ambos modelos mediante estas métricas, se observa que los dos proporcionan resultados muy similares y presentan algunas limitaciones en la resolución del problema. Dado que las métricas son tan parecidas entre ambos modelos lo que dificulta decantarse entre uno u otro, hemos decidido **seleccionar como ganador a LightGBM** observando los resultados de las curvas anteriormente mostradas y al ser conscientes de que es un algoritmo empleado en mayor medida que AdaBoosting en la actualidad. Sin embargo, cabe destacar nuevamente que **AdaBoosting presenta métricas muy similares al modelo seleccionado**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d017a",
   "metadata": {},
   "source": [
    "### Del notebook 9 (09_Explicabilidad) concluimos que:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d5d51",
   "metadata": {},
   "source": [
    "- Los valores de las siguientes variables están **aumentando la predicción del modelo en comparación con el valor esperado:'email_is_free'=0, 'housing_status'=2, 'name_email_similarity'=0.6506**. Por el contrario, los valores de estas otras variables están **disminuyendo la predicción del modelo en comparación con el valor esperado: 'device_os'=0, 'income'=0.9, 'current_address_months_count'=61, 'phone_home_valid'=0**.\n",
    "\n",
    "- Tanto el estado de la residencia del solicitante (**'housing_status'**) como el sistema operativo del dispositivo desde el que se realiza la solicitud (**'device_os'**) como la validez del teléfono móvil entregado (**'phone_home_valid'**) tienen una **elevada importancia en todas las instancias del conjunto de test**. Por el contrario, el medio online en el que se realizó la solicitud (**'source'**), si el país de origen de la solicitud es diferente al país del banco (**'foreign_request'**) y el tipo de pago del crédito (**'payment_type'**) **no poseen una importancia significativa en las instancias del conjunto de test**. Como se comprobará posteriormente, estas últimas variables coinciden con las menos importantes según el análisis de importancia que se realizará en el último apartado (con la librería Sklearn).\n",
    "\n",
    "- Existen distintos comportamientos en función de los valores de cada variables sobre la variable target 'fraud_bool':\n",
    "    - En los casos en los que las variables **'phone_home_valid', 'keep_alive_session' y 'has_other_cards' toman valores altos contribuyen en mayor medida** al SHAP value 1 y viceversa, a que la **solicitud sea fraudulenta**. \n",
    "    - Por el contrario, la variable **'email_is_free' al tomar valores bajos contribuye en mayor medida** a un SHAP de 1, a que **la solicitud sea fraudulenta**. \n",
    "    - En las variables **'housing_status', 'device_os', 'name_email_similarity' y 'prev_adress_months_count'** a simple vista se podría afirmar que cuando toman valores bajos contribuyen en mayor medida a que la solicitud sea fraudulenta; sin embargo, dado que tienen puntos solapados de ambos colores por debajo de 0 **tanto valores altos como bajos de estas variables hacen que la probabilidad de que sea fraude la solicitud sea más alta o baja**.\n",
    "    - Al contrario que en el caso anterior, con las variables **'current_adress_months_count' e 'income'** valores altos contribuyen a que la solicitud sea fraudulenta pero, a su vez puesto que existen puntos solapados de ambos colores por debajo de 0 **tanto valores altos como bajos de estas variables hacen que la probabilidad de que sea fraude la solicitud sea más alta o baja**. \n",
    "    \n",
    "- Por último, al realizar un **análisis de importancia** con la librería Sklearn se observa que las variables con **mayor importancia dentro del modelo son: 'name_email_similarity', 'current_adress_months_count' y 'bank_branch_count_8w'**. Por el contrario, las variables que presentan una menor importancia dentro de este análisis son: 'source', 'foreign_request' y 'payment_type'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b7bea",
   "metadata": {},
   "source": [
    "### ¿Hay overfitting?\n",
    "\n",
    "[Información](https://aws.amazon.com/es/what-is/overfitting/)\n",
    "\n",
    "Como explica Amazon, \"El **sobreajuste** es un comportamiento de aprendizaje automático no deseado que se produce cuando el modelo de aprendizaje automático proporciona predicciones precisas para los datos de entrenamiento, pero no para los datos nuevos\". En otras palabras, el overfitting se refiere a la situación en la que el modelo se ajusta demasiado a los detalles idiosincráticos del conjunto de entrenamiento y tiene dificultades para generalizar a datos no vistos. Si el rendimiento en el conjunto de entrenamiento es significativamente mejor que en el conjunto de validación/test, podría ser una indicación de overfitting.\n",
    "\n",
    "Tras comprobar los resultados de las métricas del classification report tanto en 'y_train_red_und_total' como en 'y_test' observamos: \n",
    "\n",
    " * Por un lado, que dichas métricas mejoran ligeramente en el dataset de test. \n",
    " * Por otro lado, acierta más cuando la variable objetivo 'fraud_bool' toma valor 0, lo cual se consideraría normal puesto que 'fraud_bool' toma en muchas más ocasiones el valor 0 que 1.\n",
    " * Además, al estar balanceado nuestro conjunto train es lógico que presente menos precisión en el valor 1 de la variable target.\n",
    "\n",
    "Por tanto, podemos concluir que nuestro modelo no presentaria overfiting; aspecto que dota de robustez al modelo seleccionado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f784aed4",
   "metadata": {},
   "source": [
    "### Resumen\n",
    "\n",
    "En resumen, tras llevar a cabo los siguientes pasos en este orden: \n",
    "- Realizar una **exploración inicial** de los datos.\n",
    "- Tratar las **correlaciones, los missings y outliers**.\n",
    "- Realizar la **selección de variables** con métodos como la regularización de Ridge y Lasso y el conocimiento del conjunto de datos adquirido en los notebooks previos.\n",
    "- Llevar acabo la **división en train y test** para a continuación poner en práctica la **ingeniería de variables**: combinación de variables, estadarización e imputación de missings.\n",
    "- Dividir el **conjunto de entrenamiento en train y validation** y balancear los datos de train con la técnica del **undersampling**.\n",
    "- **Aplicar los siguientes algoritmos**: Modelo base con imputación a la clase mayoritaria, Árbol de decisión, Bayes, Support Vector Machine, Random Forest, BaggingClassifier, XGBoost, AdaBoosting y LightGBM sobre los **datasets que contienen las variables seleccionadas por los datasets de Ridge y Lasso** ('X_train_sel_und', 'X_val_sel', 'y_train_sel_std_und' e 'y_val_sel') y sobre los **conjuntos de datos obtenidos tras la selección de variables y la feature ingeneering realizadas previamente** ('X_train_red_und', 'X_val_red', 'y_train_red_und' e 'y_val_red'). **Importante**: únicamente se han empleado los datasets no estandarizados al no emplear modelos de regresión y la validación no está balanceada.\n",
    "- Observar que **se obtienen mejores rendimientos al modelizar con los datasets 'red' que con los datasets 'sel' para todos los algoritmos** y decantarnos por estos datasets 'red' al proporcionar mejores valores en métricas como f1-score.\n",
    "- Concluir que los **modelos candidatos a ser los mejores modelos para este proyecto son LightGBM y AdaBoosting** de los datasets 'red' al presentan los mayores f1-scores con unos valores ambos de un 90% y 9% de aciertos cuando la variable objetivo toma los valores 0 y 1, respectivamente.\n",
    "- **Optimizar los parámetros de estos dos modelos** a través de una búsqueda grid, realizar las **modificaciones previas del train sobre el conjunto de test** y **evaluar los dos modelos** con sus parámetros ya optimizados con **distintas métricas**: matriz de confusión, curva Roc, curva de ganancias, curva Lift, curva de precisión y sensibilidad y curva F1-Score.\n",
    "\n",
    "Se ha concluido que el **modelo ganador para el problema planteado a lo largo de este proyecto es LightGBM**, apuntando a que AdaBoosting presenta métricas muy similares al modelo seleccionado; sin embargo, el modelo escogido es más empleado a día de hoy y consideramos que puede ser más adecuado para la resolución del problema planteado.\n",
    "\n",
    "Además, se ha estudiado la **explicabilidad de dicho modelo a través de la técnica SHAP (SHapley Additive exPlanations) y un análisis de importancia de Sklearn**. De esta forma, no solo se ha seleccionado un modelo ganador para el problema objeto de este trabajo sino que también se ha tratado de explicar con dicho modelo la importancia que poseen las variables 'finales' (las obtenidas tras realizar las tareas de preporcesamiento, imputación de missings, combinación y eliminación de variables, etcétera). Además este último apartado dota de mayor transparencia al modelo, aspecto fundamental en el panorama legislativo actual de la IA.\n",
    "\n",
    "Por último, comprobamos la existencia o no de overfiting en nuestro modelo final, concluyendo que el modelo no estaría sobreajustado (aspecto fundamental en Machine Learning)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel 1",
   "language": "python",
   "name": "kernel-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
